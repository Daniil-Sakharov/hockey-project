---
description: Common code patterns and examples for the project
---

# Code Patterns & Best Practices

## Интерфейсы для расширяемости

### Scraper Interface
```go
// Каждый парсер должен реализовать этот интерфейс
type Scraper interface {
    // Уникальное имя парсера
    Name() string
    
    // Базовый URL источника
    BaseURL() string
    
    // Парсинг данных
    Scrape(ctx context.Context) ([]models.Player, error)
    
    // Парсинг статистики для конкретного игрока
    ScrapePlayerStats(ctx context.Context, playerID string) ([]models.GameStats, error)
}
```

### Repository Interface
```go
type PlayerRepository interface {
    Create(ctx context.Context, player *models.Player) error
    Update(ctx context.Context, player *models.Player) error
    FindByID(ctx context.Context, id int64) (*models.Player, error)
    FindByName(ctx context.Context, name string) ([]*models.Player, error)
    FindByAgeRange(ctx context.Context, minAge, maxAge int) ([]*models.Player, error)
    FindByTeam(ctx context.Context, team string) ([]*models.Player, error)
}
```

## Context и Timeout

### Всегда использовать context
```go
func (s *HockeyDbScraper) Scrape(ctx context.Context) ([]models.Player, error) {
    // Установить таймаут для парсинга
    ctx, cancel := context.WithTimeout(ctx, 5*time.Minute)
    defer cancel()
    
    // Использовать ctx во всех HTTP запросах
    req, err := http.NewRequestWithContext(ctx, "GET", url, nil)
    if err != nil {
        return nil, err
    }
    
    // ...
}
```

## Error Handling Pattern

### Обертывание ошибок
```go
import "fmt"

func (r *playerRepo) Create(ctx context.Context, player *models.Player) error {
    query := `INSERT INTO players (...) VALUES (...)`
    
    _, err := r.db.ExecContext(ctx, query, /* args */)
    if err != nil {
        return fmt.Errorf("failed to create player %s: %w", player.FullName(), err)
    }
    
    return nil
}
```

### Обработка специфичных ошибок
```go
import "errors"

var (
    ErrPlayerNotFound = errors.New("player not found")
    ErrDuplicatePlayer = errors.New("player already exists")
)

func (r *playerRepo) FindByID(ctx context.Context, id int64) (*models.Player, error) {
    var player models.Player
    err := r.db.GetContext(ctx, &player, "SELECT * FROM players WHERE id = $1", id)
    
    if err == sql.ErrNoRows {
        return nil, ErrPlayerNotFound
    }
    if err != nil {
        return nil, fmt.Errorf("failed to find player: %w", err)
    }
    
    return &player, nil
}
```

## Retry Pattern для HTTP

### С exponential backoff
```go
func retryableHTTPGet(ctx context.Context, url string, maxRetries int) (*http.Response, error) {
    var resp *http.Response
    var err error
    
    for i := 0; i < maxRetries; i++ {
        req, _ := http.NewRequestWithContext(ctx, "GET", url, nil)
        resp, err = http.DefaultClient.Do(req)
        
        if err == nil && resp.StatusCode == http.StatusOK {
            return resp, nil
        }
        
        if resp != nil {
            resp.Body.Close()
        }
        
        // Exponential backoff
        waitTime := time.Duration(math.Pow(2, float64(i))) * time.Second
        log.Warnf("Request failed, retrying in %v... (attempt %d/%d)", waitTime, i+1, maxRetries)
        
        select {
        case <-time.After(waitTime):
            continue
        case <-ctx.Done():
            return nil, ctx.Err()
        }
    }
    
    return nil, fmt.Errorf("max retries exceeded: %w", err)
}
```

## Worker Pool для параллельного парсинга

```go
type ScraperJob struct {
    Scraper Scraper
    Result  chan ScraperResult
}

type ScraperResult struct {
    ScraperName string
    Players     []models.Player
    Error       error
}

func runScrapersInParallel(ctx context.Context, scrapers []Scraper, maxWorkers int) []ScraperResult {
    jobs := make(chan ScraperJob, len(scrapers))
    results := make([]ScraperResult, 0, len(scrapers))
    
    // Start workers
    var wg sync.WaitGroup
    for i := 0; i < maxWorkers; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            for job := range jobs {
                players, err := job.Scraper.Scrape(ctx)
                job.Result <- ScraperResult{
                    ScraperName: job.Scraper.Name(),
                    Players:     players,
                    Error:       err,
                }
            }
        }()
    }
    
    // Send jobs
    resultChans := make([]chan ScraperResult, 0, len(scrapers))
    for _, scraper := range scrapers {
        resultChan := make(chan ScraperResult, 1)
        resultChans = append(resultChans, resultChan)
        jobs <- ScraperJob{Scraper: scraper, Result: resultChan}
    }
    close(jobs)
    
    // Collect results
    for _, resultChan := range resultChans {
        results = append(results, <-resultChan)
    }
    
    wg.Wait()
    return results
}
```

## Rate Limiter

```go
import "golang.org/x/time/rate"

type RateLimitedScraper struct {
    BaseScraper
    limiter *rate.Limiter
}

func NewRateLimitedScraper(requestsPerSecond float64) *RateLimitedScraper {
    return &RateLimitedScraper{
        limiter: rate.NewLimiter(rate.Limit(requestsPerSecond), 1),
    }
}

func (s *RateLimitedScraper) fetch(ctx context.Context, url string) (*http.Response, error) {
    // Wait for rate limiter
    if err := s.limiter.Wait(ctx); err != nil {
        return nil, err
    }
    
    req, _ := http.NewRequestWithContext(ctx, "GET", url, nil)
    return http.DefaultClient.Do(req)
}
```

## Logging Pattern

```go
import "github.com/sirupsen/logrus"

// Инициализация логгера
var log = logrus.New()

func InitLogger(level string) {
    log.SetFormatter(&logrus.JSONFormatter{})
    
    lvl, err := logrus.ParseLevel(level)
    if err != nil {
        lvl = logrus.InfoLevel
    }
    log.SetLevel(lvl)
}

// Использование
func (s *HockeyDbScraper) Scrape(ctx context.Context) ([]models.Player, error) {
    log.WithFields(logrus.Fields{
        "scraper": s.Name(),
        "url":     s.BaseURL(),
    }).Info("Starting scraping")
    
    // ... scraping logic ...
    
    log.WithFields(logrus.Fields{
        "scraper":      s.Name(),
        "players_found": len(players),
    }).Info("Scraping completed")
    
    return players, nil
}
```

## Database Transaction Pattern

```go
func (s *ScraperService) SaveScrapedData(ctx context.Context, players []models.Player, stats []models.GameStats) error {
    // Начать транзакцию
    tx, err := s.db.BeginTxx(ctx, nil)
    if err != nil {
        return fmt.Errorf("failed to begin transaction: %w", err)
    }
    defer tx.Rollback() // откатится только если не был Commit
    
    // Сохранить игроков
    for _, player := range players {
        if err := s.playerRepo.CreateTx(ctx, tx, &player); err != nil {
            return fmt.Errorf("failed to save player: %w", err)
        }
    }
    
    // Сохранить статистику
    for _, stat := range stats {
        if err := s.statsRepo.CreateTx(ctx, tx, &stat); err != nil {
            return fmt.Errorf("failed to save stats: %w", err)
        }
    }
    
    // Зафиксировать изменения
    if err := tx.Commit(); err != nil {
        return fmt.Errorf("failed to commit transaction: %w", err)
    }
    
    return nil
}
```

## Graceful Shutdown Pattern

```go
func main() {
    ctx, cancel := context.WithCancel(context.Background())
    defer cancel()
    
    // Канал для получения сигналов ОС
    sigChan := make(chan os.Signal, 1)
    signal.Notify(sigChan, os.Interrupt, syscall.SIGTERM)
    
    // Запуск сервисов
    go runBot(ctx)
    go runScheduler(ctx)
    
    // Ожидание сигнала остановки
    <-sigChan
    log.Info("Shutting down gracefully...")
    
    // Отмена контекста для всех горутин
    cancel()
    
    // Дать время на завершение
    time.Sleep(5 * time.Second)
    
    log.Info("Shutdown complete")
}
```
